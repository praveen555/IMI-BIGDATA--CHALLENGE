{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ada1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def accuracy(y, t):\\n    return np.mean(y[y>0] == t[y>0])'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, string\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def accuracy(y, t):\n",
    "    return np.mean(y == t)\n",
    "\n",
    "\"\"\"def accuracy(y, t):\n",
    "    return np.mean(y[y>0] == t[y>0])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e89619ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_n = pd.read_csv(\"UofT_nodes.csv\")\n",
    "    df_n.dropna(inplace=True)\n",
    "    df_occupation = pd.read_csv(\"UofT_occupation_risk.csv\")\n",
    "    df_n[\"birth_year\"]=df_n[\"BIRTH_DT\"].str.split(\"-\").str[0]\n",
    "    df_n[\"cust_add_year\"]=df_n[\"CUST_ADD_DT\"].str.split(\"-\").str[0]\n",
    "    df_n[\"ocptn_risk\"]=df_n[\"OCPTN_NM\"].map(df_occupation.set_index(\"code\")[\"occupation_risk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74ccf4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 988820 entries, 0 to 999999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   RES_CNTRY_CA            988820 non-null  int64  \n",
      " 1   CNTRY_OF_INCOME_CA      988820 non-null  int64  \n",
      " 2   PEP_FL                  988820 non-null  float64\n",
      " 3   CASH_SUM_IN             988820 non-null  int32  \n",
      " 4   CASH_CNT_IN             988820 non-null  float64\n",
      " 5   CASH_SUM_OUT            988820 non-null  int32  \n",
      " 6   CASH_CNT_OUT            988820 non-null  float64\n",
      " 7   WIRES_SUM_IN            988820 non-null  int32  \n",
      " 8   WIRES_CNT_IN            988820 non-null  float64\n",
      " 9   WIRES_SUM_OUT           988820 non-null  int32  \n",
      " 10  WIRES_CNT_OUT           988820 non-null  float64\n",
      " 11  COUNTRY_RISK_INCOME     988820 non-null  object \n",
      " 12  COUNTRY_RISK_RESIDENCY  988820 non-null  object \n",
      " 13  RISK                    988820 non-null  object \n",
      " 14  GENDER                  988820 non-null  object \n",
      " 15  birth_year              988820 non-null  object \n",
      " 16  cust_add_year           988820 non-null  object \n",
      " 17  ocptn_risk              988820 non-null  object \n",
      "dtypes: float64(5), int32(4), int64(2), object(7)\n",
      "memory usage: 128.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    cols=[\"CASH_SUM_IN\",\"CASH_SUM_OUT\",\"WIRES_SUM_IN\",\"WIRES_SUM_OUT\"]\n",
    "    df_n[cols]=df_n[cols].astype(int)\n",
    "    df_n.drop([\"BIRTH_DT\",\"CUST_ADD_DT\",\"CUSTOMER_ID\",\"NAME\",\"OCPTN_NM\"],axis=1,inplace=True)\n",
    "    #df_n=pd.get_dummies(df_n,prefix={\"GENDER\":\"is\",\"COUNTRY_RISK_INCOME\":\"inc_risk\",\"COUNTRY_RISK_RESIDENCY\":\"res_risk\"},columns=[\"GENDER\",\"COUNTRY_RISK_INCOME\",\"COUNTRY_RISK_RESIDENCY\"],drop_first=True)\n",
    "    df_n.info()\n",
    "    #df_n.drop([\"GENDER\",\"is_Female\",\"COUNTRY_RISK_INCOME\",\"COUNTRY_RISK_RESIDENCY\"],axis=1,inplace=True)\n",
    "    pd.unique(df_n[\"GENDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89356ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Female' 'Low' 'Low']\n",
      " ['Male' 'Low' 'Low']\n",
      " ['Male' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']\n",
      " ['Male' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']\n",
      " ['Female' 'Low' 'Low']]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_cat=df_n[[\"GENDER\",\"COUNTRY_RISK_INCOME\",\"COUNTRY_RISK_RESIDENCY\"]].astype('str').to_numpy()\n",
    "X=df_n.iloc[:,np.r_[0:10,15:17]].to_numpy()\n",
    "t=df_n.iloc[:,13].astype('str').to_numpy()\n",
    "enc=OneHotEncoder(handle_unknown='ignore',drop=[\"Female\",\"Low\",\"Low\"],sparse_output=False)\n",
    "X_cat_enc=enc.fit_transform(X_cat)\n",
    "print(X_cat[:10,:])\n",
    "print(X_cat_enc[:10,:])\n",
    "X=np.concatenate((X,X_cat_enc),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b13371c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, t_train, t_valid = train_test_split(X,t,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7abe4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at depth  5  training acc:  0.9464599941633173\n",
      "at depth  5  validation acc:  0.9460501742818039\n",
      "at depth  10  training acc:  0.9501108102875866\n",
      "at depth  10  validation acc:  0.9491852241392097\n",
      "at depth  15  training acc:  0.963373371435506\n",
      "at depth  15  validation acc:  0.953378774701159\n",
      "at depth  20  training acc:  0.9861624389243168\n",
      "at depth  20  validation acc:  0.9542687243381\n",
      "at depth  25  training acc:  0.9976884425014519\n",
      "at depth  25  validation acc:  0.9542619822953958\n"
     ]
    }
   ],
   "source": [
    "for depth in [5,10,15,20,25]:\n",
    "    \n",
    "    clf=RandomForestClassifier(n_estimators=20,max_depth=depth, random_state=30)\n",
    "    clf.fit(X_train,t_train)\n",
    "    print(\"at depth \",depth,\" training acc: \",accuracy(clf.predict(X_train),t_train))\n",
    "    print(\"at depth \",depth,\" validation acc: \",accuracy(clf.predict(X_valid),t_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1dea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(clf.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559edc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
